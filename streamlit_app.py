import streamlit as st
import pandas as pd
from datetime import datetime, timedelta

# --- 1. é¡µé¢åŸºæœ¬é…ç½® ---
st.set_page_config(page_title="å½±åƒç§‘ç®¡ç†ç³»ç»Ÿ", page_icon="ğŸ¥", layout="wide")

# --- 2. é…ç½®ä¿¡æ¯ï¼ˆè¯·æ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹è¿™å‡ é¡¹ï¼‰ ---
# å»ºè®®ä½ åœ¨ Streamlit Secrets é‡Œè®¾ç½®äº† public_gsheet_url
BASE_URL = st.secrets.get("public_gsheet_url", "ä½ çš„Googleè¡¨æ ¼åœ°å€")

# ä½ çš„æ ‡ç­¾é¡µ ID
MANUAL_GID = "1955581250"              # æ‰‹åŠ¨å¡«å†™çš„æ ‡ç­¾é¡µ (é€šå¸¸æ˜¯ 0)
FORM_GID = "720850282"  # <--- è¯·åœ¨æ­¤å¤„å¡«å…¥é‚£ä¸²é•¿æ•°å­—

# ä½ çš„ Google è¡¨å•åµŒå…¥é“¾æ¥
# æ³¨æ„ï¼šç»“å°¾ä¸€å®šè¦å¸¦ ?embedded=true
form_url = "https://forms.gle/AzUyPeRgJnnAgEbj8?embedded=true"

# --- 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def fetch_sheet(gid):
    try:
        clean_url = BASE_URL.strip()
        base_id = clean_url.split("/d/")[1].split("/")[0]
        csv_url = f"https://docs.google.com/spreadsheets/d/{base_id}/export?format=csv&gid={gid}"
        return pd.read_csv(csv_url, on_bad_lines='skip')
    except Exception as e:
        st.error(f"è¯»å–æ ‡ç­¾é¡µ {gid} å¤±è´¥ã€‚é”™è¯¯: {e}")
        return pd.DataFrame()

@st.cache_data(ttl=60)
def get_merged_data():
    df_manual = fetch_sheet(MANUAL_GID)
    df_form = fetch_sheet(FORM_GID)
    
    columns = ['æ—¥æœŸ', 'å¸¸è§„CTäºº', 'å¸¸è§„CTéƒ¨ä½', 'å¸¸è§„DRäºº', 'å¸¸è§„DRéƒ¨ä½', 'æŸ¥ä½“CT', 'æŸ¥ä½“DR', 'æŸ¥ä½“é€è§†']
    
    if not df_form.empty:
        # æˆªå±æ˜¾ç¤ºï¼šè¡¨å•è¡¨ç¬¬ä¸€åˆ—æ˜¯æ—¶é—´æˆ³ï¼Œéœ€è¦åˆ‡æ‰
        if len(df_form.columns) > 8:
            df_form = df_form.iloc[:, 1:]
        df_form.columns = columns
    
    if not df_manual.empty:
        df_manual.columns = columns
        
    combined = pd.concat([df_manual, df_form], ignore_index=True)
    
    # å…³é”®ç‚¹ï¼šå¼ºåˆ¶è½¬æ¢ä¸ºæ—¥æœŸï¼Œå¹¶æŠ¹å»å…·ä½“æ—¶é—´ï¼Œåªä¿ç•™å¹´æœˆæ—¥
    combined['æ—¥æœŸ'] = pd.to_datetime(combined['æ—¥æœŸ'], errors='coerce').dt.normalize()
    return combined.dropna(subset=['æ—¥æœŸ'])

# --- 4. ç•Œé¢é€»è¾‘ ---

st.sidebar.title("ğŸ‘¨â€âš•ï¸ Andy çš„ç®¡ç†åå°")
menu = st.sidebar.radio("è¯·é€‰æ‹©åŠŸèƒ½", ["ğŸ“Š æŸ¥çœ‹ä¸šåŠ¡æŠ¥è¡¨", "ğŸ“ æ¯æ—¥æ•°æ®å½•å…¥"])

if menu == "ğŸ“ æ¯æ—¥æ•°æ®å½•å…¥":
    st.header("ğŸ“ æ¯æ—¥å½±åƒå·¥ä½œé‡ä¸ŠæŠ¥")
    st.components.v1.iframe(form_url, height=900, scrolling=True)

else:
    st.header("ğŸ“Š å½±åƒä¸šåŠ¡æ±‡æ€»çœ‹æ¿")
    st.markdown("---")
    
    try:
        df = get_merged_data()
        
        # --- ä¿®æ­£åçš„æ—¥æœŸè®¡ç®—é€»è¾‘ ---
        # è®¾å®šä»Šå¤©ä¸ºåŸºå‡†ï¼ŒæŠ¹å»æ—¶é—´
        today = pd.Timestamp.now().normalize() 
        # æ‰¾åˆ°æœ€è¿‘çš„å‘¨å›› (weekday: 0=Mon, 3=Thu, 6=Sun)
        # å¦‚æœä»Šå¤©æ˜¯å‘¨äº”(4)ã€å‘¨å…­(5)ã€å‘¨æ—¥(6)ï¼Œå‘¨å››åœ¨æœªæ¥ï¼›å¦‚æœä»Šå¤©æ˜¯å‘¨ä¸€è‡³å‘¨å››ï¼Œå‘¨å››åœ¨ä»Šå¤©æˆ–è¿‡å»
        days_to_thursday = (3 - today.weekday() + 7) % 7
        if today.weekday() > 3: # å¦‚æœè¿‡äº†å‘¨å››ï¼Œåˆ™å–æœ¬å‘¨å››
             end_week = today + pd.Timedelta(days=days_to_thursday)
        else: # å¦‚æœåœ¨å‘¨å››ä¹‹å‰æˆ–å½“å¤©ï¼Œè®¡ç®—é€»è¾‘ä¸€è‡´
             end_week = today + pd.Timedelta(days=days_to_thursday)
        
        # ä¿®æ­£ï¼šAndy çš„é€»è¾‘æ˜¯ç»Ÿè®¡ã€å½“å‰å‘¨æœŸã€‘ã€‚
        # å¦‚æœä»Šå¤©æ˜¯å‘¨å››ï¼Œend_week å°±æ˜¯ä»Šå¤©ï¼›start_week æ˜¯ä¸Šå‘¨äº”ï¼ˆ6å¤©å‰ï¼‰
        # å¦‚æœä»Šå¤©æ˜¯å‘¨äº”ï¼Œend_week æ˜¯ä¸‹å‘¨å››ï¼›start_week æ˜¯ä»Šå¤©
        day_of_week = today.weekday()
        if day_of_week == 4: # ä»Šå¤©æ˜¯å‘¨äº”
            start_week = today
            end_week = today + pd.Timedelta(days=6)
        else: # ä»Šå¤©æ˜¯å‘¨å…­è‡³ä¸‹å‘¨å››
            # æ‰¾åˆ°ä¹‹å‰çš„é‚£ä¸ªå‘¨äº”
            days_since_friday = (today.weekday() - 4 + 7) % 7
            start_week = today - pd.Timedelta(days=days_since_friday)
            end_week = start_week + pd.Timedelta(days=6)

        # å†æ¬¡ç¡®ä¿èŒƒå›´è¾¹ç•Œæ˜¯çº¯æ—¥æœŸ
        start_week = start_week.normalize()
        end_week = end_week.normalize()

        # ç­›é€‰ï¼šä½¿ç”¨å¼ºåˆ¶åŒ…å«è¾¹ç•Œçš„æ–¹æ³•
        mask = (df['æ—¥æœŸ'] >= start_week) & (df['æ—¥æœŸ'] <= end_week)
        week_data = df.loc[mask]

        if not week_data.empty:
            ct_p = int(week_data['å¸¸è§„CTäºº'].sum())
            ct_s = int(week_data['å¸¸è§„CTéƒ¨ä½'].sum())
            dr_p = int(week_data['å¸¸è§„DRäºº'].sum())
            dr_s = int(week_data['å¸¸è§„DRéƒ¨ä½'].sum())
            pe_ct = int(week_data['æŸ¥ä½“CT'].sum())
            pe_dr = int(week_data['æŸ¥ä½“DR'].sum())
            pe_ts = int(week_data['æŸ¥ä½“é€è§†'].sum())

            # æ ¸å¿ƒå¡ç‰‡
            c1, c2, c3 = st.columns(3)
            c1.metric("å¸¸è§„ CT éƒ¨ä½", f"{ct_s}")
            c2.metric("å¸¸è§„ DR éƒ¨ä½", f"{dr_s}")
            c3.metric("æ€»æŸ¥ä½“é‡", f"{pe_ct + pe_dr + pe_ts}")

            st.subheader("ğŸ“‹ æŠ¥è¡¨æ–‡å­— (å·²åŒ…å«ä¸Šå‘¨äº”æ•°æ®)")
            report_text = f"{start_week.strftime('%Yå¹´%mæœˆ%dæ—¥')}è‡³{end_week.strftime('%Yå¹´%mæœˆ%dæ—¥')}å½±åƒç§‘å·¥ä½œé‡ï¼š\n" \
                          f"CTï¼š{ct_p}äººï¼Œ{ct_s}éƒ¨ä½\n" \
                          f"DRï¼š{dr_p}äººï¼Œ{dr_s}éƒ¨ä½\n\n" \
                          f"æŸ¥ä½“ï¼š\n" \
                          f"é€è§†ï¼š{pe_ts}éƒ¨ä½\n" \
                          f"æ‹ç‰‡: {pe_dr}éƒ¨ä½\n" \
                          f"CT: {pe_ct}éƒ¨ä½"
            
            st.text_area("å¤åˆ¶å‘è‡³å¾®ä¿¡ç¾¤ï¼š", value=report_text, height=220)
            st.caption(f"å½“å‰ç»Ÿè®¡å‘¨æœŸï¼š{start_week.date()} (å‘¨äº”) 00:00 åˆ° {end_week.date()} (å‘¨å››) 23:59")
        else:
            st.warning(f"ğŸ“… å‘¨æœŸ {start_week.date()} è‡³ {end_week.date()} æš‚æ— æ•°æ®ã€‚")

    except Exception as e:
        st.error(f"æ•°æ®å¤„ç†å¼‚å¸¸: {e}")

if st.sidebar.button("ğŸ”„ ç«‹å³å¼ºåˆ¶åˆ·æ–°"):
    st.cache_data.clear()
    st.rerun()
